{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f238b88-3456-4410-92eb-b6b291c0b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from alpha101 import Alpha101 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca531c4-db02-49d1-9ae7-0643f619f08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>returns</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71611</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>45.07</td>\n",
       "      <td>45.35</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45.08</td>\n",
       "      <td>1824755</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.143333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71612</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>45.17</td>\n",
       "      <td>45.18</td>\n",
       "      <td>44.45</td>\n",
       "      <td>44.60</td>\n",
       "      <td>2915405</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.010648</td>\n",
       "      <td>44.743333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71613</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>44.81</td>\n",
       "      <td>44.95</td>\n",
       "      <td>44.50</td>\n",
       "      <td>44.62</td>\n",
       "      <td>2373731</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>44.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71614</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>44.81</td>\n",
       "      <td>45.24</td>\n",
       "      <td>44.68</td>\n",
       "      <td>44.75</td>\n",
       "      <td>2052338</td>\n",
       "      <td>A</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>44.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71615</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>44.72</td>\n",
       "      <td>44.78</td>\n",
       "      <td>44.36</td>\n",
       "      <td>44.58</td>\n",
       "      <td>3826245</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.003799</td>\n",
       "      <td>44.573333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   open   high    low  close   volume Name   returns  \\\n",
       "71611 2013-02-08  45.07  45.35  45.00  45.08  1824755    A  0.000000   \n",
       "71612 2013-02-11  45.17  45.18  44.45  44.60  2915405    A -0.010648   \n",
       "71613 2013-02-12  44.81  44.95  44.50  44.62  2373731    A  0.000448   \n",
       "71614 2013-02-13  44.81  45.24  44.68  44.75  2052338    A  0.002913   \n",
       "71615 2013-02-14  44.72  44.78  44.36  44.58  3826245    A -0.003799   \n",
       "\n",
       "            vwap  \n",
       "71611  45.143333  \n",
       "71612  44.743333  \n",
       "71613  44.690000  \n",
       "71614  44.890000  \n",
       "71615  44.573333  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = pd.read_csv(\"C:/Users/z1883/Desktop/507_Final_Project/Project Code/NYC Stock Price/all_stocks_5yr.csv\")\n",
    "\n",
    "prices['date'] = pd.to_datetime(prices['date'])\n",
    "prices = prices.sort_values(['Name', 'date'])\n",
    "\n",
    "# We do some data cleaning, replace NA values to 0\n",
    "prices['returns'] = prices.groupby('Name')['close'].pct_change()\n",
    "prices['returns'] = prices['returns'].replace([np.inf, -np.inf], np.nan)\n",
    "prices['returns'] = prices['returns'].fillna(0.0)\n",
    "\n",
    "# calculate the Volume-weighted average price\n",
    "tp = (prices['high'] + prices['low'] + prices['close']) / 3.0\n",
    "prices['vwap'] = (tp * prices['volume']) / prices['volume']\n",
    "\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1394e6-1ac4-4218-8f1b-d4b645b2aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to convert the long-format price DataFrame into a\n",
    "# date × stock name for a single field (e.g., 'close', 'open', etc.).\n",
    "def make_panel_field(df, field):\n",
    "    return df.pivot(index='date', columns='Name', values=field).sort_index()\n",
    "\n",
    "close  = make_panel_field(prices, 'close')\n",
    "open_  = make_panel_field(prices, 'open') \n",
    "high   = make_panel_field(prices, 'high')\n",
    "low    = make_panel_field(prices, 'low')\n",
    "volume = make_panel_field(prices, 'volume')\n",
    "returns = make_panel_field(prices, 'returns')\n",
    "vwap   = make_panel_field(prices, 'vwap')\n",
    "\n",
    "volume = prices.pivot(index='date', columns='Name', values='volume').sort_index()\n",
    "\n",
    "# Since some later formulas involve log(volume), replace zeros with 1\n",
    "# to avoid taking log(0), which would be negative infinity.\n",
    "volume = volume.replace(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33eb0ed8-2b81-4186-96f5-4a6add7a0db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>XL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-08</th>\n",
       "      <td>45.08</td>\n",
       "      <td>14.75</td>\n",
       "      <td>78.90</td>\n",
       "      <td>67.8542</td>\n",
       "      <td>36.25</td>\n",
       "      <td>46.89</td>\n",
       "      <td>34.41</td>\n",
       "      <td>73.31</td>\n",
       "      <td>39.12</td>\n",
       "      <td>45.70</td>\n",
       "      <td>...</td>\n",
       "      <td>28.24</td>\n",
       "      <td>37.51</td>\n",
       "      <td>88.61</td>\n",
       "      <td>42.87</td>\n",
       "      <td>31.84</td>\n",
       "      <td>27.09</td>\n",
       "      <td>65.30</td>\n",
       "      <td>75.85</td>\n",
       "      <td>24.14</td>\n",
       "      <td>33.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-11</th>\n",
       "      <td>44.60</td>\n",
       "      <td>14.46</td>\n",
       "      <td>78.39</td>\n",
       "      <td>68.5614</td>\n",
       "      <td>35.85</td>\n",
       "      <td>46.76</td>\n",
       "      <td>34.26</td>\n",
       "      <td>73.07</td>\n",
       "      <td>38.64</td>\n",
       "      <td>46.08</td>\n",
       "      <td>...</td>\n",
       "      <td>28.31</td>\n",
       "      <td>37.46</td>\n",
       "      <td>88.28</td>\n",
       "      <td>42.84</td>\n",
       "      <td>31.96</td>\n",
       "      <td>27.46</td>\n",
       "      <td>64.55</td>\n",
       "      <td>75.65</td>\n",
       "      <td>24.21</td>\n",
       "      <td>33.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "      <td>44.62</td>\n",
       "      <td>14.27</td>\n",
       "      <td>78.60</td>\n",
       "      <td>66.8428</td>\n",
       "      <td>35.42</td>\n",
       "      <td>46.96</td>\n",
       "      <td>34.30</td>\n",
       "      <td>73.37</td>\n",
       "      <td>38.89</td>\n",
       "      <td>46.27</td>\n",
       "      <td>...</td>\n",
       "      <td>28.41</td>\n",
       "      <td>37.58</td>\n",
       "      <td>88.46</td>\n",
       "      <td>42.87</td>\n",
       "      <td>31.84</td>\n",
       "      <td>27.95</td>\n",
       "      <td>64.75</td>\n",
       "      <td>75.44</td>\n",
       "      <td>24.49</td>\n",
       "      <td>33.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Name            A    AAL    AAP     AAPL   ABBV    ABC    ABT    ACN   ADBE  \\\n",
       "date                                                                          \n",
       "2013-02-08  45.08  14.75  78.90  67.8542  36.25  46.89  34.41  73.31  39.12   \n",
       "2013-02-11  44.60  14.46  78.39  68.5614  35.85  46.76  34.26  73.07  38.64   \n",
       "2013-02-12  44.62  14.27  78.60  66.8428  35.42  46.96  34.30  73.37  38.89   \n",
       "\n",
       "Name          ADI  ...     XL   XLNX    XOM   XRAY    XRX    XYL    YUM  \\\n",
       "date               ...                                                    \n",
       "2013-02-08  45.70  ...  28.24  37.51  88.61  42.87  31.84  27.09  65.30   \n",
       "2013-02-11  46.08  ...  28.31  37.46  88.28  42.84  31.96  27.46  64.55   \n",
       "2013-02-12  46.27  ...  28.41  37.58  88.46  42.87  31.84  27.95  64.75   \n",
       "\n",
       "Name          ZBH   ZION    ZTS  \n",
       "date                             \n",
       "2013-02-08  75.85  24.14  33.05  \n",
       "2013-02-11  75.65  24.21  33.26  \n",
       "2013-02-12  75.44  24.49  33.74  \n",
       "\n",
       "[3 rows x 505 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9286cf-22e2-4c3f-990b-f90a1395bf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>XL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-08</th>\n",
       "      <td>45.35</td>\n",
       "      <td>15.12</td>\n",
       "      <td>79.72</td>\n",
       "      <td>68.4014</td>\n",
       "      <td>36.42</td>\n",
       "      <td>46.895</td>\n",
       "      <td>34.66</td>\n",
       "      <td>73.710</td>\n",
       "      <td>39.45</td>\n",
       "      <td>45.90</td>\n",
       "      <td>...</td>\n",
       "      <td>28.74</td>\n",
       "      <td>37.630</td>\n",
       "      <td>88.80</td>\n",
       "      <td>42.88</td>\n",
       "      <td>32.12</td>\n",
       "      <td>27.64</td>\n",
       "      <td>65.49</td>\n",
       "      <td>75.99</td>\n",
       "      <td>24.21</td>\n",
       "      <td>33.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-11</th>\n",
       "      <td>45.18</td>\n",
       "      <td>15.01</td>\n",
       "      <td>78.91</td>\n",
       "      <td>69.2771</td>\n",
       "      <td>36.18</td>\n",
       "      <td>47.000</td>\n",
       "      <td>34.49</td>\n",
       "      <td>73.270</td>\n",
       "      <td>39.05</td>\n",
       "      <td>46.14</td>\n",
       "      <td>...</td>\n",
       "      <td>28.54</td>\n",
       "      <td>37.575</td>\n",
       "      <td>88.51</td>\n",
       "      <td>42.90</td>\n",
       "      <td>32.02</td>\n",
       "      <td>27.53</td>\n",
       "      <td>65.19</td>\n",
       "      <td>75.98</td>\n",
       "      <td>24.30</td>\n",
       "      <td>33.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "      <td>44.95</td>\n",
       "      <td>14.51</td>\n",
       "      <td>78.63</td>\n",
       "      <td>68.9114</td>\n",
       "      <td>35.90</td>\n",
       "      <td>47.050</td>\n",
       "      <td>34.50</td>\n",
       "      <td>73.495</td>\n",
       "      <td>39.13</td>\n",
       "      <td>46.35</td>\n",
       "      <td>...</td>\n",
       "      <td>28.61</td>\n",
       "      <td>37.710</td>\n",
       "      <td>88.62</td>\n",
       "      <td>42.99</td>\n",
       "      <td>32.12</td>\n",
       "      <td>28.10</td>\n",
       "      <td>65.06</td>\n",
       "      <td>75.82</td>\n",
       "      <td>24.57</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Name            A    AAL    AAP     AAPL   ABBV     ABC    ABT     ACN   ADBE  \\\n",
       "date                                                                            \n",
       "2013-02-08  45.35  15.12  79.72  68.4014  36.42  46.895  34.66  73.710  39.45   \n",
       "2013-02-11  45.18  15.01  78.91  69.2771  36.18  47.000  34.49  73.270  39.05   \n",
       "2013-02-12  44.95  14.51  78.63  68.9114  35.90  47.050  34.50  73.495  39.13   \n",
       "\n",
       "Name          ADI  ...     XL    XLNX    XOM   XRAY    XRX    XYL    YUM  \\\n",
       "date               ...                                                     \n",
       "2013-02-08  45.90  ...  28.74  37.630  88.80  42.88  32.12  27.64  65.49   \n",
       "2013-02-11  46.14  ...  28.54  37.575  88.51  42.90  32.02  27.53  65.19   \n",
       "2013-02-12  46.35  ...  28.61  37.710  88.62  42.99  32.12  28.10  65.06   \n",
       "\n",
       "Name          ZBH   ZION    ZTS  \n",
       "date                             \n",
       "2013-02-08  75.99  24.21  33.48  \n",
       "2013-02-11  75.98  24.30  33.50  \n",
       "2013-02-12  75.82  24.57  34.00  \n",
       "\n",
       "[3 rows x 505 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed4cc5b1-e125-48d5-93a5-f01b6d9a5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = {\n",
    "    'close': close,\n",
    "    'open': open_,\n",
    "    'high': high,\n",
    "    'low': low,\n",
    "    'volume': volume,\n",
    "    'returns': returns,\n",
    "    'vwap': vwap,\n",
    "}\n",
    "\n",
    "# Using the alpha function we write to calculate the alpha factor values.\n",
    "alpha = Alpha101(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5b661d-0241-4375-924f-226bb5cc7815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha001: The effective ratio 95.66%\n",
      "alpha002: The effective ratio 100.00%\n",
      "alpha003: The effective ratio 100.00%\n",
      "alpha004: The effective ratio 96.70%\n",
      "alpha006: The effective ratio 100.00%\n",
      "alpha007: The effective ratio 94.39%\n",
      "alpha008: The effective ratio 96.21%\n",
      "alpha011: The effective ratio 97.12%\n",
      "alpha012: The effective ratio 97.28%\n",
      "alpha013: The effective ratio 97.04%\n",
      "alpha014: The effective ratio 97.12%\n",
      "alpha015: The effective ratio 99.84%\n",
      "alpha016: The effective ratio 97.03%\n",
      "alpha017: The effective ratio 95.48%\n",
      "alpha018: The effective ratio 97.03%\n",
      "alpha019: delete (The effective value ratio is too low：77.36%)\n",
      "alpha020: The effective ratio 97.28%\n",
      "alpha022: The effective ratio 95.81%\n",
      "alpha025: The effective ratio 95.80%\n",
      "alpha026: The effective ratio 99.84%\n",
      "alpha028: The effective ratio 97.36%\n",
      "alpha029: The effective ratio 96.54%\n",
      "alpha030: The effective ratio 95.81%\n",
      "alpha032: delete (The effective value ratio is too low：78.43%)\n",
      "alpha033: The effective ratio 97.36%\n",
      "alpha034: The effective ratio 97.28%\n",
      "alpha035: The effective ratio 94.81%\n",
      "alpha037: The effective ratio 81.11%\n",
      "alpha038: The effective ratio 96.63%\n",
      "alpha040: The effective ratio 96.62%\n",
      "alpha041: The effective ratio 97.36%\n",
      "alpha042: The effective ratio 97.36%\n",
      "alpha043: The effective ratio 94.25%\n",
      "alpha044: The effective ratio 100.00%\n",
      "alpha052: delete (The effective value ratio is too low：78.14%)\n",
      "alpha053: The effective ratio 96.64%\n",
      "alpha054: The effective ratio 97.36%\n",
      "alpha060: The effective ratio 96.63%\n",
      "alpha101: The effective ratio 97.36%\n"
     ]
    }
   ],
   "source": [
    "# This step is selecting alpha factors with sufficiently many valid values.\n",
    "# For each candidate alpha factor function in 'alpha_names', we:\n",
    "# First, compute the factor values using the price data as input.\n",
    "# Second, compute the proportion of outputs that are finite (not NaN or Infinite).\n",
    "# Third, if this proportion is below a predefined threshold, we discard the factor, otherwise, we keep it as a usable factor.\n",
    "\n",
    "# This step ensures that we only keep alpha factors that behave\n",
    "# reasonably well numerically before using them in the subsequent modeling.\n",
    "\n",
    "alpha_names = [\n",
    "    'alpha001', 'alpha002', 'alpha003', 'alpha004',\n",
    "    'alpha006', 'alpha007', 'alpha008', 'alpha011', \n",
    "    'alpha012', 'alpha013', 'alpha014', 'alpha015', \n",
    "    'alpha016', 'alpha017', 'alpha018', 'alpha019',\n",
    "    'alpha020', 'alpha022', 'alpha025', 'alpha026',\n",
    "    'alpha028', 'alpha029', 'alpha030', 'alpha032', \n",
    "    'alpha033', 'alpha034', 'alpha035', 'alpha037', \n",
    "    'alpha038', 'alpha040', 'alpha041', 'alpha042', \n",
    "    'alpha043', 'alpha044', 'alpha052', 'alpha053', \n",
    "    'alpha054', 'alpha060', 'alpha101',\n",
    "]\n",
    "\n",
    "usable = {}   \n",
    "bad    = {}  \n",
    "\n",
    "for name in alpha_names:\n",
    "    func = getattr(alpha, name)\n",
    "    try:\n",
    "        fac = func()\n",
    "        arr = fac.to_numpy()\n",
    "        finite_ratio = np.isfinite(arr).mean()\n",
    "        \n",
    "        # Threhold = 0.8\n",
    "        if finite_ratio < 0.8:  \n",
    "            bad[name] = f\"The effective value ratio is too low：{finite_ratio:.2%}\"\n",
    "            print(f\"{name}: delete ({bad[name]})\")\n",
    "            continue\n",
    "\n",
    "        usable[name] = fac\n",
    "        print(f\"{name}: The effective ratio {finite_ratio:.2%}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        bad[name] = f\"Error: {repr(e)}\"\n",
    "        print(f\"{name}: Fail to calculate -> {bad[name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c924053-a784-4756-be88-66604fbce7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = pd.concat(usable, axis=1)\n",
    "factors.index.name = 'date'\n",
    "factors.columns.names = ['alpha', 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bfadc75-db90-42dd-a976-c1ba0da81fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-sectional z-score calculation \n",
    "def cs_zscore(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize each day's cross-section of values across stocks.\n",
    "    We treat each row as one trading day and each column as one stock.\n",
    "    For every date t, we compute:\n",
    "        z_{i,t} = (x_{i,t} - mean_t) / std_t\n",
    "    where mean_t and std_t are the cross-sectional mean and standard\n",
    "    deviation across all stocks on day t.\n",
    "    \n",
    "    This makes the values comparable across time and focuses the model\n",
    "    on relative differences between stocks on the same day, rather\n",
    "    than on the absolute level of the variable.\n",
    "    \"\"\"\n",
    "    # Cross-sectional mean and standard deviation across stocks (columns)\n",
    "    mean = df.mean(axis=1)\n",
    "    std = df.std(axis=1)\n",
    "\n",
    "    # If for some day all stocks have exactly the same value, the\n",
    "    # cross-sectional std would be 0.  To avoid division by zero, we\n",
    "    # replace 0 with 1 so that the corresponding z-scores become 0.\n",
    "    std = std.replace(0, 1)\n",
    "    \n",
    "    # Subtract the daily cross-sectional mean and divide by the\n",
    "    # daily cross-sectional standard deviation.\n",
    "    return df.sub(mean, axis=0).div(std, axis=0)\n",
    "\n",
    "\n",
    "# We start from 'close' prices and compute log returns over\n",
    "# a horizon of H trading days for each stock:\n",
    "# r_{i, t to t+H} = log(P_{i, t+H}) − log(P_{i, t})\n",
    "\n",
    "# Intuitively, this measures how much stock i goes up or down over the\n",
    "# next H days, on a log scale, starting from day t.\n",
    "H = 5 \n",
    "\n",
    "symbols = sorted(factors.columns.get_level_values('Name').unique())\n",
    "close_sub = close[symbols].sort_index()\n",
    "\n",
    "log_price = np.log(close_sub)\n",
    "log_ret_fwd = log_price.shift(-H) - log_price \n",
    "y_raw = log_ret_fwd\n",
    "\n",
    "# As in the factor construction, we standardized the forward returns\n",
    "# cross-sectionally. This means that for each day t, we converted the\n",
    "# raw returns into z-scores across stocks. The model is therefore\n",
    "# trained to predict which stocks will perform better or worse\n",
    "# relative to other stocks on the same day, rather than predicting\n",
    "# the absolute size of returns.\n",
    "y = cs_zscore(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abd8004f-c54b-4337-89e1-e2448ce53af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid alpha factors: 36 ['alpha001', 'alpha002', 'alpha003', 'alpha004', 'alpha006', 'alpha007', 'alpha008', 'alpha011', 'alpha012', 'alpha013'] ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th colspan=\"10\" halign=\"left\">alpha001</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">alpha101</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>XL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-04-21</th>\n",
       "      <td>1.010930</td>\n",
       "      <td>1.010930</td>\n",
       "      <td>1.010930</td>\n",
       "      <td>1.010930</td>\n",
       "      <td>1.010930</td>\n",
       "      <td>-1.079597</td>\n",
       "      <td>-0.217445</td>\n",
       "      <td>1.010930</td>\n",
       "      <td>1.010930</td>\n",
       "      <td>-1.632748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.620463</td>\n",
       "      <td>-0.263020</td>\n",
       "      <td>1.740996</td>\n",
       "      <td>-0.377818</td>\n",
       "      <td>-0.735473</td>\n",
       "      <td>0.602375</td>\n",
       "      <td>1.095045</td>\n",
       "      <td>-0.297801</td>\n",
       "      <td>-0.285868</td>\n",
       "      <td>1.183843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-22</th>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>-1.414709</td>\n",
       "      <td>-0.904166</td>\n",
       "      <td>-0.397521</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158113</td>\n",
       "      <td>-0.099065</td>\n",
       "      <td>-0.961593</td>\n",
       "      <td>-1.351729</td>\n",
       "      <td>0.976544</td>\n",
       "      <td>0.335605</td>\n",
       "      <td>1.450526</td>\n",
       "      <td>-1.545718</td>\n",
       "      <td>1.489270</td>\n",
       "      <td>0.618461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-23</th>\n",
       "      <td>1.205370</td>\n",
       "      <td>1.205370</td>\n",
       "      <td>1.205370</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>1.205370</td>\n",
       "      <td>-1.525314</td>\n",
       "      <td>-1.112363</td>\n",
       "      <td>-0.744056</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066905</td>\n",
       "      <td>0.295582</td>\n",
       "      <td>-0.203261</td>\n",
       "      <td>-0.029474</td>\n",
       "      <td>1.229480</td>\n",
       "      <td>0.576228</td>\n",
       "      <td>-1.291116</td>\n",
       "      <td>-0.016322</td>\n",
       "      <td>0.645839</td>\n",
       "      <td>-1.484964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-24</th>\n",
       "      <td>1.139743</td>\n",
       "      <td>1.139743</td>\n",
       "      <td>1.139743</td>\n",
       "      <td>1.139743</td>\n",
       "      <td>0.141537</td>\n",
       "      <td>1.139743</td>\n",
       "      <td>-1.657469</td>\n",
       "      <td>-1.322250</td>\n",
       "      <td>-0.662987</td>\n",
       "      <td>1.139743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208201</td>\n",
       "      <td>-1.307533</td>\n",
       "      <td>-1.001937</td>\n",
       "      <td>-1.572670</td>\n",
       "      <td>-0.055063</td>\n",
       "      <td>0.084266</td>\n",
       "      <td>-0.481236</td>\n",
       "      <td>-1.100133</td>\n",
       "      <td>-1.663658</td>\n",
       "      <td>2.090296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-25</th>\n",
       "      <td>0.647243</td>\n",
       "      <td>0.647243</td>\n",
       "      <td>0.647243</td>\n",
       "      <td>1.467329</td>\n",
       "      <td>-0.202263</td>\n",
       "      <td>0.647243</td>\n",
       "      <td>-0.202263</td>\n",
       "      <td>-1.585009</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>0.647243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116334</td>\n",
       "      <td>1.059119</td>\n",
       "      <td>1.901715</td>\n",
       "      <td>-0.045189</td>\n",
       "      <td>-1.062140</td>\n",
       "      <td>-0.089338</td>\n",
       "      <td>2.100520</td>\n",
       "      <td>0.298683</td>\n",
       "      <td>0.274443</td>\n",
       "      <td>1.639684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "alpha       alpha001                                                    \\\n",
       "Name               A       AAL       AAP      AAPL      ABBV       ABC   \n",
       "date                                                                     \n",
       "2014-04-21  1.010930  1.010930  1.010930  1.010930  1.010930 -1.079597   \n",
       "2014-04-22  0.892475  0.892475  0.892475  0.892475  0.892475 -1.414709   \n",
       "2014-04-23  1.205370  1.205370  1.205370  0.048364  1.205370 -1.525314   \n",
       "2014-04-24  1.139743  1.139743  1.139743  1.139743  0.141537  1.139743   \n",
       "2014-04-25  0.647243  0.647243  0.647243  1.467329 -0.202263  0.647243   \n",
       "\n",
       "alpha                                               ...  alpha101            \\\n",
       "Name             ABT       ACN      ADBE       ADI  ...        XL      XLNX   \n",
       "date                                                ...                       \n",
       "2014-04-21 -0.217445  1.010930  1.010930 -1.632748  ... -0.620463 -0.263020   \n",
       "2014-04-22 -0.904166 -0.397521  0.892475  0.892475  ... -0.158113 -0.099065   \n",
       "2014-04-23 -1.112363 -0.744056  0.048364  0.048364  ...  2.066905  0.295582   \n",
       "2014-04-24 -1.657469 -1.322250 -0.662987  1.139743  ...  0.208201 -1.307533   \n",
       "2014-04-25 -0.202263 -1.585009 -0.967187  0.647243  ... -0.116334  1.059119   \n",
       "\n",
       "alpha                                                                   \\\n",
       "Name             XOM      XRAY       XRX       XYL       YUM       ZBH   \n",
       "date                                                                     \n",
       "2014-04-21  1.740996 -0.377818 -0.735473  0.602375  1.095045 -0.297801   \n",
       "2014-04-22 -0.961593 -1.351729  0.976544  0.335605  1.450526 -1.545718   \n",
       "2014-04-23 -0.203261 -0.029474  1.229480  0.576228 -1.291116 -0.016322   \n",
       "2014-04-24 -1.001937 -1.572670 -0.055063  0.084266 -0.481236 -1.100133   \n",
       "2014-04-25  1.901715 -0.045189 -1.062140 -0.089338  2.100520  0.298683   \n",
       "\n",
       "alpha                           \n",
       "Name            ZION       ZTS  \n",
       "date                            \n",
       "2014-04-21 -0.285868  1.183843  \n",
       "2014-04-22  1.489270  0.618461  \n",
       "2014-04-23  0.645839 -1.484964  \n",
       "2014-04-24 -1.663658  2.090296  \n",
       "2014-04-25  0.274443  1.639684  \n",
       "\n",
       "[5 rows x 18180 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_alphas = sorted(usable.keys())\n",
    "print(\"Number of valid alpha factors:\", len(selected_alphas), selected_alphas[:10], \"...\")\n",
    "\n",
    "def cs_zscore_factor_panel(factors_dict):\n",
    "    \"\"\"\n",
    "    Apply cross-sectional z-score normalization to each alpha factor panel\n",
    "    and stack them into a single MultiIndex DataFrame.\n",
    "    \"\"\"\n",
    "    z_dict = {}\n",
    "    for name, fac in factors_dict.items():\n",
    "        # Make sure rows are sorted by date for this factor\n",
    "        fac = fac.sort_index()\n",
    "        \n",
    "        # For this factor, standardize each day's cross-section across stocks\n",
    "        fac_z = cs_zscore(fac)          \n",
    "        z_dict[name] = fac_z\n",
    "\n",
    "    # first level = factor name and second level = stock name.\n",
    "    out = pd.concat(z_dict, axis=1)\n",
    "    out.index.name = 'date'\n",
    "    out.columns.names = ['alpha', 'Name']\n",
    "    return out\n",
    "\n",
    "# Build the full standardized factor panel:\n",
    "# rows = dates, columns = (alpha, stock), values = z-scored factor values.\n",
    "factors_z = cs_zscore_factor_panel(usable)\n",
    "factors_z.iloc[300:305].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40ad5fbd-4cf4-4422-8dc6-9a76871ded98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((503609, 20, 36), (503609,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lookback window length (number of past trading days used as input)\n",
    "L = 20    \n",
    "\n",
    "# Forward return horizon in days\n",
    "H = 5           \n",
    "alpha_list = selected_alphas\n",
    "symbols = sorted(factors_z.columns.get_level_values('Name').unique())\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "date_list = []\n",
    "sym_list = []\n",
    "\n",
    "for sym in symbols:\n",
    "    # Extract the factor panel for a single stock:\n",
    "    # rows = dates, columns = alpha factors\n",
    "    fac_sym = (\n",
    "        factors_z\n",
    "        # select this stock across all alpha factors\n",
    "        .xs(sym, axis=1, level='Name')   \n",
    "        [alpha_list]\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    # Extract the corresponding H-day forward return labels for this stock:\n",
    "    # y_sym[t] is the z-scored forward H-day log return starting from date t.\n",
    "    y_sym = y[sym].sort_index()\n",
    "\n",
    "    fac_arr = fac_sym.to_numpy()  \n",
    "    y_arr = y_sym.to_numpy()      \n",
    "    dates_sym = fac_sym.index.to_numpy()\n",
    "\n",
    "    T = fac_arr.shape[0]\n",
    "\n",
    "    # For each date t, we build one training sample:\n",
    "    # Input X_t: the factor history for this stock over the last L days, (i.e., rows [t-L+1, ..., t] of fac_arr).\n",
    "    # Target y_t: the forward H-day z-scored log return starting at date t.\n",
    "    # To make sure we have L days of history and H days into the future,\n",
    "    for t in range(L - 1, T - H):\n",
    "         # Factor sequence window of length L ending at date t\n",
    "        window_X = fac_arr[t - L + 1:t + 1, :]  \n",
    "        # Corresponding forward H-day return label\n",
    "        target = y_arr[t]                        \n",
    "\n",
    "        if not np.isfinite(window_X).all():\n",
    "            continue\n",
    "        if not np.isfinite(target):\n",
    "            continue\n",
    "\n",
    "        X_list.append(window_X)\n",
    "        y_list.append(target)\n",
    "        date_list.append(dates_sym[t])   \n",
    "        sym_list.append(sym)\n",
    "\n",
    "X = np.stack(X_list).astype(np.float32)      \n",
    "y_vec = np.array(y_list, dtype=np.float32)  \n",
    "\n",
    "dates_arr = np.array(date_list)\n",
    "sym_arr = np.array(sym_list)\n",
    "\n",
    "X.shape, y_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "703b8fc5-81bb-4244-aac7-fb39a7f60f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 254118 Val: 123966 Test: 125525\n"
     ]
    }
   ],
   "source": [
    "# We split the data into train, validation, and test data set.\n",
    "\n",
    "train_end = pd.Timestamp('2016-1-31')\n",
    "val_end   = pd.Timestamp('2017-1-31')\n",
    "\n",
    "train_mask = dates_arr <= train_end\n",
    "val_mask   = (dates_arr > train_end) & (dates_arr <= val_end)\n",
    "test_mask  = dates_arr > val_end\n",
    "\n",
    "print(\"Train:\", train_mask.sum(), \"Val:\", val_mask.sum(), \"Test:\", test_mask.sum())\n",
    "\n",
    "X_train, y_train = X[train_mask], y_vec[train_mask]\n",
    "X_val,   y_val   = X[val_mask],   y_vec[val_mask]\n",
    "X_test,  y_test  = X[test_mask],  y_vec[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ed83f16-4079-4fc4-8fe4-8826d3cc7d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS MSE train: 0.98660684\n",
      "OLS MSE val  : 0.99592125\n",
      "OLS MSE test : 1.0015659\n",
      "The mean of 5-day RankIC on test set for OLS: 0.0024431491421802983\n",
      "The sd of 5-day RankIC on test set for OLS: 0.07131201266705325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Convert X from shape (N, L, K) to (N, L*K) so that it can be used by LinearRegression.\n",
    "def flatten_seq(X):\n",
    "    return X.reshape(X.shape[0], -1)\n",
    "\n",
    "np.random.seed(6)\n",
    "X_train_flat = flatten_seq(X_train)\n",
    "X_val_flat   = flatten_seq(X_val)\n",
    "X_test_flat  = flatten_seq(X_test)\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train_flat, y_train)\n",
    "\n",
    "y_pred_train = ols.predict(X_train_flat)\n",
    "y_pred_val   = ols.predict(X_val_flat)\n",
    "y_pred_test  = ols.predict(X_test_flat)\n",
    "\n",
    "\n",
    "# Report mean squared error (MSE) on train, validation, and test sets.\n",
    "# This evaluates how close the predicted z-scored returns are to the true\n",
    "# z-scored returns in a regression sense.\n",
    "print(\"OLS MSE train:\", mean_squared_error(y_train, y_pred_train))\n",
    "print(\"OLS MSE val  :\", mean_squared_error(y_val,   y_pred_val))\n",
    "print(\"OLS MSE test :\", mean_squared_error(y_test,  y_pred_test))\n",
    "\n",
    "\n",
    "# Extract the dates corresponding to each test sample, so we can compute\n",
    "# cross-sectional performance (RankIC) date by date.\n",
    "dates_test = dates_arr[test_mask]\n",
    "\n",
    "unique_dates = np.unique(dates_test)\n",
    "ic_list = []\n",
    "\n",
    "for d in unique_dates:\n",
    "     # Select all test samples for this trading day (all stocks).\n",
    "    mask_d = (dates_test == d)\n",
    "    yt_d = y_test[mask_d]\n",
    "    yp_d = y_pred_test[mask_d]\n",
    "\n",
    "    # Remove any non-finite values to avoid issues in Spearman correlation\n",
    "    valid = np.isfinite(yt_d) & np.isfinite(yp_d)\n",
    "    yt_d = yt_d[valid]\n",
    "    yp_d = yp_d[valid]\n",
    "\n",
    "    # RankIC is defined as the cross-sectional Spearman rank correlation\n",
    "    # between predicted and realized returns on a given day.\n",
    "    # Intuitively, it measures how well the model ranks stocks from\n",
    "    # \"good\" to \"bad\" relative performers on that day.\n",
    "    ic = spearmanr(yt_d, yp_d).correlation\n",
    "    if np.isfinite(ic):\n",
    "        ic_list.append(ic)\n",
    "\n",
    "if len(ic_list) == 0:\n",
    "    print(\"We can not calculate the valid RankIC value for OLS\")\n",
    "else:\n",
    "    ic_arr = np.array(ic_list)\n",
    "    mean_ic = ic_arr.mean()\n",
    "    std_ic  = ic_arr.std()\n",
    "    print(\"The mean of 5-day RankIC on test set for OLS:\", mean_ic)\n",
    "    print(\"The sd of 5-day RankIC on test set for OLS:\", std_ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ae72094-e6e1-4d4e-ae29-d172eb1077da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO MSE train: 0.993023\n",
      "LASSO MSE val  : 0.9900943\n",
      "LASSO MSE test : 0.99561924\n",
      "The mean of 5-day RankIC on test set for LASSO: -0.00032719428906715714\n",
      "The sd of 5-day RankIC on test set for LASSO: 0.09789243013900517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# In this part, we use LASSO regression: linear model with L1 penalty.\n",
    "# Compared to plain OLS, the L1 regularization encourages many\n",
    "# coefficients to be exactly zero, effectively performing feature\n",
    "# selection among the flattened factor-history inputs.\n",
    "lasso = Lasso(alpha=0.01, max_iter=10000, random_state=6)\n",
    "lasso.fit(X_train_flat, y_train)\n",
    "\n",
    "y_pred_train_lasso = lasso.predict(X_train_flat)\n",
    "y_pred_val_lasso   = lasso.predict(X_val_flat)\n",
    "y_pred_test_lasso  = lasso.predict(X_test_flat)\n",
    "\n",
    "print(\"LASSO MSE train:\", mean_squared_error(y_train, y_pred_train_lasso))\n",
    "print(\"LASSO MSE val  :\", mean_squared_error(y_val,   y_pred_val_lasso))\n",
    "print(\"LASSO MSE test :\", mean_squared_error(y_test,  y_pred_test_lasso))\n",
    "\n",
    "\n",
    "# RankIC evaluation (same as for OLS) \n",
    "# For each test date, we again compute, the Spearman rank correlation\n",
    "# between predicted and realized returns across all stocks. This tells\n",
    "# us how well LASSO ranks stocks from better to worse performers on\n",
    "# each day, in a purely cross-sectional sense.\n",
    "dates_test = dates_arr[test_mask]\n",
    "unique_dates = np.unique(dates_test)\n",
    "ic_list_lasso = []\n",
    "\n",
    "for d in unique_dates:\n",
    "    mask_d = (dates_test == d)\n",
    "    yt_d = y_test[mask_d]\n",
    "    yp_d = y_pred_test_lasso[mask_d]\n",
    "\n",
    "    valid = np.isfinite(yt_d) & np.isfinite(yp_d)\n",
    "    yt_d = yt_d[valid]\n",
    "    yp_d = yp_d[valid]\n",
    "    if len(yt_d) == 0:\n",
    "        continue\n",
    "    \n",
    "    ic = spearmanr(yt_d, yp_d).correlation\n",
    "    if np.isfinite(ic):\n",
    "        ic_list_lasso.append(ic)\n",
    "\n",
    "if len(ic_list_lasso) == 0:\n",
    "    print(\"We can not calculate the valid RankIC value for LASSO\")\n",
    "else:\n",
    "    ic_arr_lasso = np.array(ic_list_lasso)\n",
    "    mean_ic_lasso = ic_arr_lasso.mean()\n",
    "    std_ic_lasso  = ic_arr_lasso.std()\n",
    "    print(\"The mean of 5-day RankIC on test set for LASSO:\", mean_ic_lasso)\n",
    "    print(\"The sd of 5-day RankIC on test set for LASSO:\", std_ic_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4be53a2a-3434-4a59-a67f-d08bc7349ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((254118, 20, 36), (254118,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class FactorSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each sample consists of:\n",
    "        X ∈ R^{L × K} : a sequence of L days of factor values for one stock\n",
    "                        (already cross-sectionally z-scored each day),\n",
    "        y ∈ R         : the corresponding forward H-day return target for\n",
    "                        the last day in the sequence (also z-scored\n",
    "                        cross-sectionally across stocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        # X has shape (N, L, K) where:\n",
    "        # N = number of (date, stock) samples\n",
    "        # L = lookback length\n",
    "        # K = number of alpha factors\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).float().unsqueeze(-1)  # (N, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total number of samples in the dataset\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = FactorSequenceDataset(X_train, y_train)\n",
    "val_dataset   = FactorSequenceDataset(X_val,   y_val)\n",
    "test_dataset  = FactorSequenceDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c783986-1186-48e8-a2a3-804eff7594b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FactorTransformer(nn.Module):\n",
    "# Each input sample is a sequence of L days of K standardized factor values\n",
    "# for a single stock, with shape (L, K).\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,   \n",
    "        seq_len,        \n",
    "        d_model=4,\n",
    "        nhead=2,\n",
    "        num_layers=2,\n",
    "        dim_feedforward=16,\n",
    "        dropout=0.25\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.input_proj = nn.Linear(num_features, d_model)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, seq_len + 1, d_model))\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.final_ln = nn.LayerNorm(d_model)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, 1)\n",
    "        )\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.trunc_normal_(self.input_proj.weight, std=0.02)\n",
    "        nn.init.zeros_(self.input_proj.bias)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        nn.init.trunc_normal_(self.pos_embedding, std=0.02)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        bsz, L, K = x.shape\n",
    "        assert L == self.seq_len, f\"input sequence length {L} are not consistent with {self.seq_len}\"\n",
    "\n",
    "        h = self.input_proj(x)                       \n",
    "\n",
    "        cls_tokens = self.cls_token.expand(bsz, -1, -1)  \n",
    "        h = torch.cat([cls_tokens, h], dim=1)           \n",
    "\n",
    "        h = h + self.pos_embedding[:, :L+1, :]\n",
    "\n",
    "        h_enc = self.encoder(h)                        \n",
    "        cls_out = h_enc[:, 0, :]                       \n",
    "        cls_out = self.final_ln(cls_out)\n",
    "        out = self.mlp(cls_out)                        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd1001db-22bd-4a29-b887-5da09ac712cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Epoch 01 | train MSE = 0.993467\n",
      "Epoch 02 | train MSE = 0.993229\n",
      "Epoch 03 | train MSE = 0.992899\n",
      "Epoch 04 | train MSE = 0.992512\n",
      "Epoch 05 | train MSE = 0.992393\n",
      "Epoch 06 | train MSE = 0.992245\n",
      "Epoch 07 | train MSE = 0.992255\n",
      "Epoch 08 | train MSE = 0.992169\n",
      "Epoch 09 | train MSE = 0.992073\n",
      "Epoch 10 | train MSE = 0.991960\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "K = X_train.shape[2]\n",
    "L = X_train.shape[1]\n",
    "\n",
    "# Instantiate the Transformer model with relatively small capacity\n",
    "model = FactorTransformer(\n",
    "    num_features=K,\n",
    "    seq_len=L,\n",
    "    d_model=4,\n",
    "    nhead=2,\n",
    "    num_layers=2,       \n",
    "    dim_feedforward=8,\n",
    "    dropout=0.25        \n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Mean squared error loss between predicted and true z-scored returns\n",
    "criterion = nn.MSELoss()\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "\n",
    "def run_epoch(loader, model, optimizer=None, max_grad_norm=1.0):\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_n = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "        total_n += X_batch.size(0)\n",
    "\n",
    "    return total_loss / total_n\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = run_epoch(train_loader, model, optimizer)\n",
    "    val_loss   = run_epoch(val_loader,   model, optimizer=None)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train MSE = {train_loss:.6f}\")\n",
    "\n",
    "# Restore the best-performing model\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f2a87c3-a72f-4e06-9db5-b2b32ff3b15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer test MSE: 0.9956638\n",
      "The mean of 5-day RankIC on test set for Transformer: -0.0012800206223629912\n",
      "The sd of 5-day RankIC on test set for Transformer: 0.12254856610823486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "\n",
    "# Collect predictions and true targets on the test set\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        y_hat = model(X_batch)\n",
    "\n",
    "        y_true_list.append(y_batch.cpu().numpy().ravel())\n",
    "        y_pred_list.append(y_hat.cpu().numpy().ravel())\n",
    "\n",
    "y_true_all = np.concatenate(y_true_list)\n",
    "y_pred_all = np.concatenate(y_pred_list)\n",
    "\n",
    "# This is Overall regression error (MSE) on the test set\n",
    "# This treats all (stock, date) observations as independent and measures\n",
    "# the average squared difference between predicted and true z-scored forward returns.\n",
    "mse_test = mean_squared_error(y_true_all, y_pred_all)\n",
    "print(\"Transformer test MSE:\", mse_test)\n",
    "\n",
    "# We here compute RankIC for each test date, RankIC_t = Spearman rank correlation(pred_t, true_t)\n",
    "# across all stocks, and then average these daily RankIC values.\n",
    "dates_test = dates_arr[test_mask]\n",
    "\n",
    "unique_dates = np.unique(dates_test)\n",
    "ic_list = []\n",
    "\n",
    "for d in unique_dates:\n",
    "    mask_d = (dates_test == d)\n",
    "    yt_d = y_true_all[mask_d]\n",
    "    yp_d = y_pred_all[mask_d]\n",
    "\n",
    "    # Remove any NaN / infinite values\n",
    "    valid = np.isfinite(yt_d) & np.isfinite(yp_d)\n",
    "    yt_d = yt_d[valid]\n",
    "    yp_d = yp_d[valid]\n",
    "\n",
    "    # Require at least a few stocks for the cross-sectional correlation\n",
    "    if yt_d.size < 5:\n",
    "        continue\n",
    "\n",
    "    # If the model (or the true returns) are essentially constant on this day,\n",
    "    # Spearman correlation is not meaningful; we skip such days.\n",
    "    if np.allclose(yp_d, yp_d[0]) or np.allclose(yt_d, yt_d[0]):\n",
    "        continue\n",
    "\n",
    "    ic = spearmanr(yt_d, yp_d).correlation\n",
    "    if np.isfinite(ic):\n",
    "        ic_list.append(ic)\n",
    "\n",
    "if len(ic_list) == 0:\n",
    "    print(\"On all test days, the predicted or true values were too close to constants to calculate RankIC.\")\n",
    "else:\n",
    "    mean_ic = np.mean(ic_list)\n",
    "    std_ic  = np.std(ic_list)\n",
    "    print(\"The mean of 5-day RankIC on test set for Transformer:\", mean_ic)\n",
    "    print(\"The sd of 5-day RankIC on test set for Transformer:\", std_ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49e8bf6a-4a28-42ae-961b-3379ee5a51dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 125525\n",
      "OLS prediction length      : 125525\n",
      "LASSO prediction length    : 125525\n",
      "Transformer prediction length: 125525\n",
      " OLS long-short portfolio performance (Top 20% vs Bottom 20%, 5-day holding)\n",
      "Annual Return: -0.007968311624321212\n",
      "Annual Volatility: 0.04406468730783651\n",
      "Sharpe   : -0.18083213818481172\n",
      "Max Drawdown: -0.20632374\n",
      "\n",
      " LASSO long-short portfolio performance (Top 20% vs Bottom 20%, 5-day holding)\n",
      "Annual Return: -0.003195437912427823\n",
      "Annual Volatility: 0.053181902075247575\n",
      "Sharpe   : -0.06008506254452065\n",
      "Max Drawdown: -0.16522682\n",
      "\n",
      " Transformer long-short portfolio performance (Top 20% vs Bottom 20%, 5-day holding)\n",
      "Annual Return: 0.021126409528892554\n",
      "Annual Volatility: 0.06853906348678927\n",
      "Sharpe   : 0.30823895825428976\n",
      "Max Drawdown: -0.21534818\n"
     ]
    }
   ],
   "source": [
    "# Map the panel y_raw to a sample-level vector\n",
    "# For each sample (date, symbol) pair, extract the corresponding 5-day\n",
    "# forward log return from the panel y_raw, and flatten into a 1D array.\n",
    "y_raw_vec = np.array(\n",
    "    [y_raw.loc[d, s] for d, s in zip(dates_arr, sym_arr)],\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# Keep only the test-set samples\n",
    "# True 5-day log returns for the test set\n",
    "y_raw_test = y_raw_vec[test_mask]       \n",
    "dates_test = dates_arr[test_mask]       \n",
    "\n",
    "# OLS: the test-set predictions were computed earlier as y_pred_test\n",
    "y_pred_test_ols = y_pred_test\n",
    "\n",
    "# LASSO: the test-set predictions were computed earlier as y_pred_test_lasso.\n",
    "\n",
    "# In our earlier analysis, LASSO tended to have a negative RankIC, meaning\n",
    "# that higher predicted scores were associated with lower realized returns.\n",
    "# For portfolio construction, we want \"higher score = more attractive stock\",\n",
    "# so we invert the sign here before using the scores for ranking.\n",
    "y_pred_test_lasso = -y_pred_test_lasso\n",
    "\n",
    "# For Transformer model, the test-set predictions were collected into y_pred_all\n",
    "# when we ran the model over test_loader. Similarly, the Transformer’s\n",
    "# raw scores also showed a negative RankIC, so we invert the sign so\n",
    "# that larger scores correspond to better expected returns in the\n",
    "# long–short portfolio ranking.\n",
    "y_pred_test_trans = -y_pred_all\n",
    "\n",
    "print(f\"Number of test samples: {y_raw_test.shape[0]}\")\n",
    "print(f\"OLS prediction length      : {y_pred_test_ols.shape[0]}\")\n",
    "print(f\"LASSO prediction length    : {y_pred_test_lasso.shape[0]}\")\n",
    "print(f\"Transformer prediction length: {y_pred_test_trans.shape[0]}\")\n",
    "\n",
    "\n",
    "# Long–short portfolio backtest\n",
    "def long_short_portfolio_stats(y_raw_test, y_pred_test, dates_test,\n",
    "                               top_q=0.2, bottom_q=0.2, H=5):\n",
    "    \"\"\"\n",
    "    Construct a long–short portfolio based on model scores and compute\n",
    "    performance statistics.\n",
    "\n",
    "    On each test date t:\n",
    "        - Rank all stocks by the model score s_{i,t} (higher is better).\n",
    "        - Go long the top top_q fraction (e.g., top 20%) of stocks.\n",
    "        - Go short the bottom bottom_q fraction (e.g., bottom 20%) of stocks.\n",
    "        - For each stock, use the realized 5-day forward log return r_{i,t→t+H}\n",
    "          to measure performance over the H-day holding period.\n",
    "        - The long–short return for date t is the average simple return of the\n",
    "          long portfolio minus the average simple return of the short portfolio.\n",
    "    \"\"\"\n",
    "\n",
    "    unique_dates = np.unique(dates_test)\n",
    "    ls_ret_list = []\n",
    "    date_list   = []\n",
    "\n",
    "    for d in unique_dates:\n",
    "        # All test samples (stocks) corresponding to this calendar date\n",
    "        mask_d = (dates_test == d)\n",
    "\n",
    "        # 5-day forward log returns (true)\n",
    "        r_d = y_raw_test[mask_d]   \n",
    "        s_d = y_pred_test[mask_d] \n",
    "\n",
    "        # Remove NaN / non-finite values\n",
    "        valid = np.isfinite(r_d) & np.isfinite(s_d)\n",
    "        r_d = r_d[valid]\n",
    "        s_d = s_d[valid]\n",
    "\n",
    "        # Skip days with too few stocks to form meaningful portfolios\n",
    "        if r_d.size < 10:\n",
    "            continue\n",
    "\n",
    "        # Sort stocks by Alpha factor score in descending order\n",
    "        order = np.argsort(s_d)[::-1]\n",
    "        n = r_d.size\n",
    "        n_long  = int(np.floor(n * top_q))\n",
    "        n_short = int(np.floor(n * bottom_q))\n",
    "\n",
    "        if n_long == 0 or n_short == 0:\n",
    "            continue\n",
    "\n",
    "        r_long  = r_d[order[:n_long]]\n",
    "        r_short = r_d[order[-n_short:]]\n",
    "\n",
    "         # Convert 5-day log returns to simple returns: R = exp(r) - 1\n",
    "        ret_long  = np.exp(r_long)  - 1.0\n",
    "        ret_short = np.exp(r_short) - 1.0\n",
    "\n",
    "        long_port_ret  = ret_long.mean()\n",
    "        short_port_ret = ret_short.mean()\n",
    "        ls_ret = long_port_ret - short_port_ret   \n",
    "\n",
    "        ls_ret_list.append(ls_ret)\n",
    "        date_list.append(d)\n",
    "\n",
    "    ls_ret = np.array(ls_ret_list)\n",
    "    dates_out = np.array(date_list)\n",
    "\n",
    "    if ls_ret.size == 0:\n",
    "        print(\"There is no effective sequence of long and short returns.\")\n",
    "        return None\n",
    "\n",
    "    # Cumulative return curve of the long–short portfolio\n",
    "    cum_curve = (1.0 + ls_ret).cumprod()\n",
    "\n",
    "    # Annualization: treat each ls_ret as the return for one H-day holding period\n",
    "    periods_per_year = 252.0 / H\n",
    "\n",
    "    mean_ret = ls_ret.mean()\n",
    "    vol      = ls_ret.std(ddof=1)\n",
    "\n",
    "    ann_return = (1.0 + mean_ret) ** periods_per_year - 1.0\n",
    "    ann_vol    = vol * np.sqrt(periods_per_year)\n",
    "    sharpe     = ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "\n",
    "    # Maximum drawdown based on the cumulative curve\n",
    "    peak = np.maximum.accumulate(cum_curve)\n",
    "    drawdown = cum_curve / peak - 1.0\n",
    "    max_dd = drawdown.min()\n",
    "\n",
    "    stats = {\n",
    "        \"dates\": dates_out,      \n",
    "        \"ls_ret\": ls_ret,        \n",
    "        \"cum_curve\": cum_curve,  \n",
    "        \"ann_return\": ann_return,\n",
    "        \"ann_vol\": ann_vol,\n",
    "        \"sharpe\": sharpe,\n",
    "        \"max_drawdown\": max_dd,\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# Long–short backtest for OLS / LASSO / Transformer\n",
    "stats_ols    = long_short_portfolio_stats(y_raw_test, y_pred_test_ols,    dates_test, H=H)\n",
    "stats_lasso  = long_short_portfolio_stats(y_raw_test, y_pred_test_lasso,  dates_test, H=H)\n",
    "stats_trans  = long_short_portfolio_stats(y_raw_test, y_pred_test_trans,  dates_test, H=H)\n",
    "\n",
    "print(\" OLS long-short portfolio performance (Top 20% vs Bottom 20%, 5-day holding)\")\n",
    "print(\"Annual Return:\", stats_ols[\"ann_return\"])\n",
    "print(\"Annual Volatility:\", stats_ols[\"ann_vol\"])\n",
    "print(\"Sharpe   :\", stats_ols[\"sharpe\"])\n",
    "print(\"Max Drawdown:\", stats_ols[\"max_drawdown\"])\n",
    "\n",
    "print(\"\\n LASSO long-short portfolio performance (Top 20% vs Bottom 20%, 5-day holding)\")\n",
    "print(\"Annual Return:\", stats_lasso[\"ann_return\"])\n",
    "print(\"Annual Volatility:\", stats_lasso[\"ann_vol\"])\n",
    "print(\"Sharpe   :\", stats_lasso[\"sharpe\"])\n",
    "print(\"Max Drawdown:\", stats_lasso[\"max_drawdown\"])\n",
    "\n",
    "print(\"\\n Transformer long-short portfolio performance (Top 20% vs Bottom 20%, 5-day holding)\")\n",
    "print(\"Annual Return:\", stats_trans[\"ann_return\"])\n",
    "print(\"Annual Volatility:\", stats_trans[\"ann_vol\"])\n",
    "print(\"Sharpe   :\", stats_trans[\"sharpe\"])\n",
    "print(\"Max Drawdown:\", stats_trans[\"max_drawdown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aeeab4-4619-4e9e-bcf8-fff08e4922f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
